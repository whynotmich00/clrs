{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clrs._src.processors import GATv2FullD2\n",
    "import haiku as hk\n",
    "import optax\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \\\\ TODO DOWNLOAD MATPLOTLIB IN TACTIC_AI ENV\n",
    "# \\\\ TODO rendere più leggibile il codice introducendo un datastructure che consideri in maniera più compatta le x (node_fts, edge_fts, graph_fts, adj_mat, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]\n",
      " [13 14 15 16]]\n",
      "[[13 14 15 16]\n",
      " [ 9 10 11 12]\n",
      " [ 5  6  7  8]\n",
      " [ 1  2  3  4]]\n",
      "[[ 4  3  2  1]\n",
      " [ 8  7  6  5]\n",
      " [12 11 10  9]\n",
      " [16 15 14 13]]\n",
      "[[16 15 14 13]\n",
      " [12 11 10  9]\n",
      " [ 8  7  6  5]\n",
      " [ 4  3  2  1]]\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]\n",
      "  [ 9 10 11 12]\n",
      "  [13 14 15 16]]\n",
      "\n",
      " [[13 14 15 16]\n",
      "  [ 9 10 11 12]\n",
      "  [ 5  6  7  8]\n",
      "  [ 1  2  3  4]]\n",
      "\n",
      " [[ 4  3  2  1]\n",
      "  [ 8  7  6  5]\n",
      "  [12 11 10  9]\n",
      "  [16 15 14 13]]\n",
      "\n",
      " [[16 15 14 13]\n",
      "  [12 11 10  9]\n",
      "  [ 8  7  6  5]\n",
      "  [ 4  3  2  1]]]\n"
     ]
    }
   ],
   "source": [
    "# Per utilizzare il metodo d2_forward() in GATv2FullD2 bisogna aggiungere applicare le 4 proiezioni \n",
    "# degli input per node (b, n, d), edge (b, n, n, d) e graph (b, d) features \n",
    "# stack(originale, flip_verticale, flip_orizzontale, flip_verticale_orizzontale).\n",
    "# Nuova dimensione dell'input per node_fts p.e.: (4, b, n, d)\n",
    "# ESEMPIO\n",
    "mat = jnp.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])\n",
    "mat_verticale = mat[::-1, :]\n",
    "mat_orizzontale = mat[:, ::-1]\n",
    "mat_verticale_orizzontale = mat[::-1, ::-1]\n",
    "print(mat, mat_verticale, mat_orizzontale, mat_verticale_orizzontale, sep=\"\\n\")\n",
    "# poi stack sulla prima dimensione\n",
    "mats = [mat, mat_verticale, mat_orizzontale, mat_verticale_orizzontale]\n",
    "mat = jnp.stack(mats, axis=0)\n",
    "print(mat)\n",
    "# jnp.mean(jnp.stack(mats, axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(node_fts, edge_fts, graph_fts, adj_mat, hidden):\n",
    "    model = GATv2FullD2(out_size=2, nb_heads=2)\n",
    "    return model(node_fts, edge_fts, graph_fts, adj_mat, hidden) # d2_forward()\n",
    "\n",
    "model_init, model_apply = hk.transform(model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creo finte features per il grafo\n",
    "rng = jax.random.PRNGKey(0)\n",
    "# nodo\n",
    "node_fts = jax.random.normal(rng, shape=(200, 22, 4))\n",
    "# egdes\n",
    "edge_fts = jax.random.normal(rng, shape=(200, 22, 22, 1))\n",
    "# etichetta grafo\n",
    "graph_fts = jax.random.normal(rng, shape=(200, 2))\n",
    "# matrice di adiacenza\n",
    "adj_mat = jnp.ones(shape=(200, 22, 22))\n",
    "# hidden (?)\n",
    "hidden = jax.random.normal(rng, shape=(200, 22, 4))\n",
    "# labels tackle\n",
    "labels = jax.random.permutation(rng, jnp.concat([jnp.ones(100), jnp.zeros(100)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATI FLIPPATI PER IL METODO d2_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 22, 22, 1)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 200, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnode_fts = jnp.stack([node_fts,\n",
    "                     node_fts[:, ::-1, :],\n",
    "                     node_fts[:, :, ::-1],\n",
    "                     node_fts[:, ::-1, ::-1]], axis=0)\n",
    "fedge_fts = jnp.stack([edge_fts,\n",
    "                     edge_fts[:, ::-1, :],\n",
    "                     edge_fts[:, :, ::-1],\n",
    "                     edge_fts[:, ::-1, ::-1]], axis=0)\n",
    "# da valutare se graph feat deve essere flippato\n",
    "# fgraph_fts = jnp.stack([graph_fts,\n",
    "#                      graph_fts[:, ::-1, :],\n",
    "#                      graph_fts[:, :, ::-1],\n",
    "#                      graph_fts[:, ::-1, ::-1]], axis=0)\n",
    "fgraph_fts = jnp.stack((graph_fts,)*4, axis=0)\n",
    "\n",
    "fgraph_fts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 22, 22)\n"
     ]
    }
   ],
   "source": [
    "print(edge_fts.shape[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_fts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When we run `forward.init`, Haiku will run `forward_fn(x)` and collect initial\n",
    "# parameter values. Haiku requires you pass a RNG rng to `init`, since parameters\n",
    "# are typically initialized randomly:\n",
    "rng = jax.random.PRNGKey(42)\n",
    "params = model_init(rng, node_fts, edge_fts, graph_fts, adj_mat, hidden)\n",
    "\n",
    "# When we run `forward.apply`, Haiku will run `forward_fn(x)` and inject parameter\n",
    "# values from the `params` that are passed as the first argument.  Note that\n",
    "# models transformed using `hk.transform(f)` must be called with an additional\n",
    "# `rng` argument: `forward.apply(params, rng, x)`. Use\n",
    "# `hk.without_apply_rng(hk.transform(f))` if this is undesirable.\n",
    "y = model_apply(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 22, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 44)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b, n, d = y.shape\n",
    "jnp.reshape(y, (b, n*d)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ora per d2_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fwd_fn(fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden):\n",
    "    model = GATv2FullD2(out_size=2, nb_heads=2)\n",
    "    return model.d2_forward(fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)\n",
    "\n",
    "model_fwd_init, model_fwd_apply = hk.transform(model_fwd_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "\n",
    "params = model_fwd_init(rng, fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)\n",
    "\n",
    "y = model_fwd_apply(params, rng, fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.4750538, dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y[0])\n",
    "y[0][0, 0, 0]\n",
    "y[3][0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(hk.Module):\n",
    "    def __init__(self, gatv2_out_size: int, gatv2_nb_heads: int, linear_out_size: int = 2):\n",
    "        super().__init__()\n",
    "        self.gatv2 = GATv2FullD2(out_size=gatv2_out_size, nb_heads=gatv2_nb_heads)\n",
    "        self.linear = hk.Linear(output_size=linear_out_size)\n",
    "\n",
    "    def __call__(self, node_fts, edge_fts, graph_fts, adj_mat, hidden):\n",
    "        gat_output, _ = self.gatv2(node_fts, edge_fts, graph_fts, adj_mat, hidden)\n",
    "        b, n, d = gat_output.shape\n",
    "        flattened_output = jnp.reshape(gat_output, (b, n*d))  # Flat node features on last axis\n",
    "        scalar_output = self.linear(flattened_output)\n",
    "        return scalar_output\n",
    "\n",
    "def myNet_fn(node_fts, edge_fts, graph_fts, adj_mat, hidden):\n",
    "    model = myNet(gatv2_out_size=2, gatv2_nb_heads=2)\n",
    "    return model(node_fts, edge_fts, graph_fts, adj_mat, hidden)\n",
    "\n",
    "myNet_init, myNet_apply = hk.transform(myNet_fn)\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "params = myNet_init(rng, node_fts, edge_fts, graph_fts, adj_mat, hidden)\n",
    "\n",
    "# When we run `forward.apply`, Haiku will run `forward_fn(x)` and inject parameter\n",
    "# values from the `params` that are passed as the first argument.  Note that\n",
    "# models transformed using `hk.transform(f)` must be called with an additional\n",
    "# `rng` argument: `forward.apply(params, rng, x)`. Use\n",
    "# `hk.without_apply_rng(hk.transform(f))` if this is undesirable.\n",
    "y = myNet_apply(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output di d2_forward() è una lista di len uguale a 4 (da capire come utilizzare questi dati moltiplicati)\n",
    "# per 4\n",
    "class myNet_d2(hk.Module):\n",
    "    def __init__(self, gatv2_out_size: int, gatv2_nb_heads: int, linear_out_size: int = 2):\n",
    "        super().__init__()\n",
    "        self.gatv2 = GATv2FullD2(out_size=gatv2_out_size, nb_heads=gatv2_nb_heads)\n",
    "        self.linear = hk.Linear(output_size=linear_out_size)\n",
    "\n",
    "    def __call__(self, fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden):\n",
    "        gat_output = self.gatv2.d2_forward(fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)\n",
    "        b, n, d = gat_output[0].shape\n",
    "        flattened_output = jnp.reshape(jnp.array(gat_output), (b, 4*n*d))  # Flat node features on last axis\n",
    "        scalar_output = self.linear(flattened_output)\n",
    "        return scalar_output\n",
    "\n",
    "def myNet_d2_fn(fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden):\n",
    "    model = myNet_d2(gatv2_out_size=2, gatv2_nb_heads=2)\n",
    "    return model(fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)\n",
    "\n",
    "myNet_d2_init, myNet_d2_apply = hk.transform(myNet_d2_fn)\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "params = myNet_d2_init(rng, fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)\n",
    "\n",
    "# When we run `forward.apply`, Haiku will run `forward_fn(x)` and inject parameter\n",
    "# values from the `params` that are passed as the first argument.  Note that\n",
    "# models transformed using `hk.transform(f)` must be called with an additional\n",
    "# `rng` argument: `forward.apply(params, rng, x)`. Use\n",
    "# `hk.without_apply_rng(hk.transform(f))` if this is undesirable.\n",
    "y = myNet_d2_apply(params, rng, fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.ravel(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.25664264  0.15795916]\n",
      " [-0.4785112  -0.38034892]\n",
      " [-0.41137823 -0.22265594]\n",
      " [-0.43343404  0.21691099]\n",
      " [-0.18514387 -0.10827615]\n",
      " [ 0.3682926  -0.1418969 ]\n",
      " [ 0.10915945  0.4389233 ]\n",
      " [-0.07725035  0.08247987]]\n"
     ]
    }
   ],
   "source": [
    "len(params)\n",
    "print(params['my_net/~/gatv2_aggr_clrs_processor/linear'][\"w\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, y):\n",
    "    logits = myNet_apply(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden)\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits, jax.nn.one_hot(y, 2)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.7278143, dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "loss_fn(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = optax.adam(learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Initialize Parameters and Optimizer State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "params = myNet_init(rng, node_fts, edge_fts, graph_fts, adj_mat, hidden)\n",
    "\n",
    "opt_state = optimizer.init(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(params, opt_state, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, y):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'my_net/~/gatv2_aggr_clrs_processor/linear': {'b': Array([-0.00099999, -0.00099999], dtype=float32),\n",
       "   'w': Array([[ 0.25564265,  0.15695918],\n",
       "          [-0.4795112 , -0.37934893],\n",
       "          [-0.41237822, -0.22365592],\n",
       "          [-0.43243405,  0.215911  ],\n",
       "          [-0.18614386, -0.10927615],\n",
       "          [ 0.3672926 , -0.14089692],\n",
       "          [ 0.10815946,  0.4379233 ],\n",
       "          [-0.07625037,  0.08147988]], dtype=float32)},\n",
       "  'my_net/~/gatv2_aggr_clrs_processor/linear_1': {'b': Array([-0.00099999, -0.00099999], dtype=float32),\n",
       "   'w': Array([[-0.48068088,  0.6309275 ],\n",
       "          [ 0.18759483, -0.14978436],\n",
       "          [-0.44798693,  0.20787208],\n",
       "          [ 0.14497875, -0.19853099],\n",
       "          [ 0.16847068, -0.18189548],\n",
       "          [-0.378203  ,  0.02443844],\n",
       "          [ 0.04869739,  0.31703183],\n",
       "          [-0.2213596 , -0.32207504]], dtype=float32)},\n",
       "  'my_net/~/gatv2_aggr_clrs_processor/linear_2': {'b': Array([ 0.00099999, -0.00099994], dtype=float32),\n",
       "   'w': Array([[ 0.14765775,  0.08846406],\n",
       "          [ 0.13041453,  0.04534452],\n",
       "          [ 0.00098777, -0.4404898 ],\n",
       "          [-0.12357715,  0.15820874],\n",
       "          [-0.41490284, -0.24912491],\n",
       "          [-0.3764518 ,  0.12923297],\n",
       "          [-0.34514964, -0.02387353],\n",
       "          [ 0.0359482 , -0.40514907]], dtype=float32)},\n",
       "  'my_net/~/gatv2_aggr_clrs_processor/linear_3': {'b': Array([ 0.00099999, -0.00099994], dtype=float32),\n",
       "   'w': Array([[ 0.07449541, -0.13197048],\n",
       "          [ 0.15200335,  0.42593867],\n",
       "          [-0.21208765,  0.19653602],\n",
       "          [-0.53355736, -0.2607524 ],\n",
       "          [-0.02183086, -0.31241137],\n",
       "          [ 0.14876999,  0.6568944 ],\n",
       "          [-0.03044455, -0.18402414],\n",
       "          [ 0.37773484,  0.11562888]], dtype=float32)},\n",
       "  'my_net/~/gatv2_aggr_clrs_processor/linear_4': {'b': Array([ 0.00099999, -0.00099994], dtype=float32),\n",
       "   'w': Array([[0.56261575, 1.0207093 ]], dtype=float32)},\n",
       "  'my_net/~/gatv2_aggr_clrs_processor/linear_5': {'b': Array([ 0.00099999, -0.00099994], dtype=float32),\n",
       "   'w': Array([[-0.8548594 ,  0.09942587]], dtype=float32)},\n",
       "  'my_net/~/gatv2_aggr_clrs_processor/linear_6': {'b': Array([-6.239941e-05], dtype=float32),\n",
       "   'w': Array([[-1.9299837]], dtype=float32)},\n",
       "  'my_net/~/gatv2_aggr_clrs_processor/linear_7': {'b': Array([-9.782736e-06], dtype=float32),\n",
       "   'w': Array([[-0.422208]], dtype=float32)},\n",
       "  'my_net/~/linear': {'b': Array([ 0.00099999, -0.00099999], dtype=float32),\n",
       "   'w': Array([[ 0.05971343,  0.08717169],\n",
       "          [ 0.19775602, -0.04047166],\n",
       "          [-0.11409996,  0.23017064],\n",
       "          [-0.19717841, -0.16309953],\n",
       "          [-0.12418365,  0.2683361 ],\n",
       "          [-0.09616924,  0.00882338],\n",
       "          [-0.1125714 ,  0.03667286],\n",
       "          [-0.07876594, -0.18684813],\n",
       "          [ 0.08365185,  0.1139396 ],\n",
       "          [ 0.13213907,  0.03037955],\n",
       "          [-0.04603405,  0.186719  ],\n",
       "          [ 0.11843407,  0.02927684],\n",
       "          [-0.17907843, -0.13613842],\n",
       "          [ 0.04405649, -0.10390595],\n",
       "          [ 0.07519228,  0.18957238],\n",
       "          [ 0.02139581, -0.17189832],\n",
       "          [-0.08137614,  0.0797493 ],\n",
       "          [-0.21030578,  0.13528007],\n",
       "          [-0.16392268, -0.14738402],\n",
       "          [ 0.16734517,  0.05500869],\n",
       "          [-0.05016255, -0.20340586],\n",
       "          [-0.01833665,  0.12604997],\n",
       "          [-0.08991078, -0.07021428],\n",
       "          [ 0.20388728,  0.02768369],\n",
       "          [-0.28913742, -0.00583781],\n",
       "          [ 0.1697883 ,  0.06749446],\n",
       "          [ 0.04387437,  0.07234741],\n",
       "          [-0.0831185 ,  0.06520957],\n",
       "          [ 0.07928581, -0.02385888],\n",
       "          [ 0.10664206, -0.13867985],\n",
       "          [-0.1614742 , -0.00154762],\n",
       "          [ 0.04513251, -0.15145256],\n",
       "          [-0.00654072,  0.13616022],\n",
       "          [ 0.0817984 ,  0.15359761],\n",
       "          [ 0.11783661,  0.26302385],\n",
       "          [-0.11994687,  0.09238213],\n",
       "          [ 0.18290687, -0.12693605],\n",
       "          [ 0.05970625, -0.2290325 ],\n",
       "          [ 0.08959768,  0.13864408],\n",
       "          [-0.12499481,  0.1500046 ],\n",
       "          [-0.20087299, -0.28096983],\n",
       "          [-0.13680689,  0.05180494],\n",
       "          [-0.11840719,  0.05810532],\n",
       "          [ 0.01202024, -0.05963128]], dtype=float32)}},\n",
       " (ScaleByAdamState(count=Array(1, dtype=int32), mu={'my_net/~/gatv2_aggr_clrs_processor/linear': {'b': Array([0.00641783, 0.00226501], dtype=float32), 'w': Array([[ 0.00118115,  0.0006169 ],\n",
       "         [ 0.00127508, -0.00035431],\n",
       "         [ 0.00019725,  0.00029187],\n",
       "         [-0.00027586,  0.0004094 ],\n",
       "         [ 0.00118115,  0.0006169 ],\n",
       "         [ 0.00127508, -0.00035431],\n",
       "         [ 0.00019725,  0.00029187],\n",
       "         [-0.00027586,  0.0004094 ]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_1': {'b': Array([0.00641783, 0.00226501], dtype=float32), 'w': Array([[-0.0048514 , -0.00165209],\n",
       "         [-0.00247916, -0.00218831],\n",
       "         [-0.00294873,  0.0017672 ],\n",
       "         [-0.00372947, -0.00447266],\n",
       "         [-0.0048514 , -0.00165209],\n",
       "         [-0.00247916, -0.00218831],\n",
       "         [-0.00294873,  0.0017672 ],\n",
       "         [-0.00372946, -0.00447266]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_2': {'b': Array([-4.2558243e-04,  1.8669960e-05], dtype=float32), 'w': Array([[-5.81415719e-04,  1.47385235e-05],\n",
       "         [ 5.65339520e-04,  3.00393905e-04],\n",
       "         [ 8.39502958e-04, -2.13473919e-04],\n",
       "         [ 2.14416417e-03, -1.67449922e-04],\n",
       "         [-5.81415719e-04,  1.47385235e-05],\n",
       "         [ 5.65339520e-04,  3.00393905e-04],\n",
       "         [ 8.39502725e-04, -2.13473919e-04],\n",
       "         [ 2.14416417e-03, -1.67449922e-04]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_3': {'b': Array([-4.2558237e-04,  1.8669971e-05], dtype=float32), 'w': Array([[ 5.0720398e-04,  1.5890650e-05],\n",
       "         [-1.1844302e-04, -2.2468132e-05],\n",
       "         [ 2.5792790e-04, -1.1712928e-05],\n",
       "         [-2.9880716e-04, -1.5250439e-04],\n",
       "         [ 5.0720398e-04,  1.5890650e-05],\n",
       "         [-1.1844302e-04, -2.2468132e-05],\n",
       "         [ 2.5792792e-04, -1.1712940e-05],\n",
       "         [-2.9880714e-04, -1.5250439e-04]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_4': {'b': Array([-4.2558188e-04,  1.8669816e-05], dtype=float32), 'w': Array([[ 0.00059532, -0.00015427]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_5': {'b': Array([-4.2558252e-04,  1.8669944e-05], dtype=float32), 'w': Array([[1.13998474e-04, 6.09681701e-05]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_6': {'b': Array([6.655228e-11], dtype=float32), 'w': Array([[0.00012267]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_7': {'b': Array([9.879386e-12], dtype=float32), 'w': Array([[-7.504169e-05]], dtype=float32)}, 'my_net/~/linear': {'b': Array([-0.00319871,  0.00319871], dtype=float32), 'w': Array([[-2.3055940e-03,  2.3055940e-03],\n",
       "         [ 1.3108352e-03, -1.3108350e-03],\n",
       "         [ 7.4998400e-04, -7.4998382e-04],\n",
       "         [ 4.2869049e-04, -4.2869066e-04],\n",
       "         [-3.0490393e-03,  3.0490390e-03],\n",
       "         [ 1.6174046e-05, -1.6174234e-05],\n",
       "         [-2.1092778e-03,  2.1092778e-03],\n",
       "         [-8.2939415e-04,  8.2939409e-04],\n",
       "         [-3.1626143e-05,  3.1625921e-05],\n",
       "         [ 9.4261079e-04, -9.4261061e-04],\n",
       "         [-5.3656835e-04,  5.3656817e-04],\n",
       "         [ 5.8514922e-04, -5.8514922e-04],\n",
       "         [ 6.5722701e-04, -6.5722683e-04],\n",
       "         [-1.2380502e-03,  1.2380492e-03],\n",
       "         [-2.1258565e-03,  2.1258565e-03],\n",
       "         [ 1.4554207e-03, -1.4554211e-03],\n",
       "         [-2.3777653e-03,  2.3777655e-03],\n",
       "         [-4.8793871e-03,  4.8793876e-03],\n",
       "         [ 1.1346757e-05, -1.1346990e-05],\n",
       "         [ 6.7706447e-04, -6.7706424e-04],\n",
       "         [ 9.2957320e-04, -9.2957309e-04],\n",
       "         [-3.2693928e-03,  3.2693928e-03],\n",
       "         [-2.6549451e-04,  2.6549454e-04],\n",
       "         [ 1.7056678e-03, -1.7056678e-03],\n",
       "         [-9.8031515e-04,  9.8031538e-04],\n",
       "         [-3.0395989e-03,  3.0395989e-03],\n",
       "         [-2.8642260e-03,  2.8642265e-03],\n",
       "         [ 1.4250288e-03, -1.4250289e-03],\n",
       "         [-1.0429135e-03,  1.0429135e-03],\n",
       "         [-1.0680079e-03,  1.0680080e-03],\n",
       "         [-3.0836386e-03,  3.0836393e-03],\n",
       "         [-2.6286638e-03,  2.6286636e-03],\n",
       "         [-1.3789360e-03,  1.3789359e-03],\n",
       "         [-4.3258071e-05,  4.3257980e-05],\n",
       "         [-5.1747268e-04,  5.1747268e-04],\n",
       "         [-3.7868009e-03,  3.7868011e-03],\n",
       "         [-2.9916686e-04,  2.9916695e-04],\n",
       "         [ 3.2448521e-04, -3.2448568e-04],\n",
       "         [-1.3475533e-03,  1.3475535e-03],\n",
       "         [-1.0534896e-03,  1.0534894e-03],\n",
       "         [ 1.9396562e-03, -1.9396562e-03],\n",
       "         [-2.4781283e-03,  2.4781283e-03],\n",
       "         [-6.2640657e-04,  6.2640646e-04],\n",
       "         [-2.8804247e-03,  2.8804250e-03]], dtype=float32)}}, nu={'my_net/~/gatv2_aggr_clrs_processor/linear': {'b': Array([4.118852e-06, 5.130291e-07], dtype=float32), 'w': Array([[1.3951168e-07, 3.8056918e-08],\n",
       "         [1.6258267e-07, 1.2553406e-08],\n",
       "         [3.8907575e-09, 8.5187111e-09],\n",
       "         [7.6100717e-09, 1.6761003e-08],\n",
       "         [1.3951168e-07, 3.8056918e-08],\n",
       "         [1.6258267e-07, 1.2553406e-08],\n",
       "         [3.8907593e-09, 8.5187075e-09],\n",
       "         [7.6100735e-09, 1.6761003e-08]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_1': {'b': Array([4.1188478e-06, 5.1302874e-07], dtype=float32), 'w': Array([[2.3536054e-06, 2.7294030e-07],\n",
       "         [6.1462310e-07, 4.7887096e-07],\n",
       "         [8.6950325e-07, 3.1230132e-07],\n",
       "         [1.3908915e-06, 2.0004709e-06],\n",
       "         [2.3536054e-06, 2.7294030e-07],\n",
       "         [6.1462310e-07, 4.7887096e-07],\n",
       "         [8.6950303e-07, 3.1230132e-07],\n",
       "         [1.3908908e-06, 2.0004713e-06]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_2': {'b': Array([1.8112040e-08, 3.4856746e-11], dtype=float32), 'w': Array([[3.3804426e-08, 2.1722409e-11],\n",
       "         [3.1960877e-08, 9.0236503e-09],\n",
       "         [7.0476524e-08, 4.5571116e-09],\n",
       "         [4.5974394e-07, 2.8039480e-09],\n",
       "         [3.3804426e-08, 2.1722409e-11],\n",
       "         [3.1960877e-08, 9.0236503e-09],\n",
       "         [7.0476489e-08, 4.5571116e-09],\n",
       "         [4.5974394e-07, 2.8039480e-09]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_3': {'b': Array([1.8112036e-08, 3.4856781e-11], dtype=float32), 'w': Array([[2.57255870e-08, 2.52512750e-11],\n",
       "         [1.40287493e-09, 5.04816952e-11],\n",
       "         [6.65268063e-09, 1.37192688e-11],\n",
       "         [8.92857255e-09, 2.32575892e-09],\n",
       "         [2.57255870e-08, 2.52512750e-11],\n",
       "         [1.40287493e-09, 5.04816952e-11],\n",
       "         [6.65268152e-09, 1.37192965e-11],\n",
       "         [8.92856988e-09, 2.32575892e-09]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_4': {'b': Array([1.8111994e-08, 3.4856205e-11], dtype=float32), 'w': Array([[3.5440532e-08, 2.3799054e-09]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_5': {'b': Array([1.8112049e-08, 3.4856677e-11], dtype=float32), 'w': Array([[1.2995652e-09, 3.7171180e-10]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_6': {'b': Array([4.4292053e-22], dtype=float32), 'w': Array([[1.5046714e-09]], dtype=float32)}, 'my_net/~/gatv2_aggr_clrs_processor/linear_7': {'b': Array([9.760227e-24], dtype=float32), 'w': Array([[5.6312544e-10]], dtype=float32)}, 'my_net/~/linear': {'b': Array([1.0231749e-06, 1.0231752e-06], dtype=float32), 'w': Array([[5.31576347e-07, 5.31576347e-07],\n",
       "         [1.71828901e-07, 1.71828859e-07],\n",
       "         [5.62476039e-08, 5.62475755e-08],\n",
       "         [1.83775537e-08, 1.83775697e-08],\n",
       "         [9.29664111e-07, 9.29663997e-07],\n",
       "         [2.61599787e-11, 2.61605806e-11],\n",
       "         [4.44905254e-07, 4.44905254e-07],\n",
       "         [6.87894683e-08, 6.87894541e-08],\n",
       "         [1.00021297e-10, 1.00019902e-10],\n",
       "         [8.88515075e-08, 8.88514720e-08],\n",
       "         [2.87905575e-08, 2.87905433e-08],\n",
       "         [3.42399602e-08, 3.42399602e-08],\n",
       "         [4.31947313e-08, 4.31947136e-08],\n",
       "         [1.53276815e-07, 1.53276588e-07],\n",
       "         [4.51926610e-07, 4.51926610e-07],\n",
       "         [2.11824968e-07, 2.11825068e-07],\n",
       "         [5.65376808e-07, 5.65376865e-07],\n",
       "         [2.38084203e-06, 2.38084226e-06],\n",
       "         [1.28748904e-11, 1.28754186e-11],\n",
       "         [4.58416274e-08, 4.58416025e-08],\n",
       "         [8.64106298e-08, 8.64106156e-08],\n",
       "         [1.06889286e-06, 1.06889286e-06],\n",
       "         [7.04873360e-09, 7.04873582e-09],\n",
       "         [2.90930245e-07, 2.90930245e-07],\n",
       "         [9.61017719e-08, 9.61018287e-08],\n",
       "         [9.23916161e-07, 9.23916161e-07],\n",
       "         [8.20379057e-07, 8.20379285e-07],\n",
       "         [2.03070712e-07, 2.03070741e-07],\n",
       "         [1.08766855e-07, 1.08766855e-07],\n",
       "         [1.14064079e-07, 1.14064122e-07],\n",
       "         [9.50882679e-07, 9.50883134e-07],\n",
       "         [6.90987349e-07, 6.90987235e-07],\n",
       "         [1.90146451e-07, 1.90146423e-07],\n",
       "         [1.87126079e-10, 1.87125274e-10],\n",
       "         [2.67777978e-08, 2.67777978e-08],\n",
       "         [1.43398609e-06, 1.43398643e-06],\n",
       "         [8.95008068e-09, 8.95008601e-09],\n",
       "         [1.05290656e-08, 1.05290958e-08],\n",
       "         [1.81590011e-07, 1.81590039e-07],\n",
       "         [1.10984026e-07, 1.10983990e-07],\n",
       "         [3.76226637e-07, 3.76226637e-07],\n",
       "         [6.14112025e-07, 6.14112025e-07],\n",
       "         [3.92385253e-08, 3.92385076e-08],\n",
       "         [8.29684666e-07, 8.29684780e-07]], dtype=float32)}}),\n",
       "  EmptyState()),\n",
       " Array(0.7278143, dtype=float32))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "train_step(params, opt_state, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 0.9068794250488281\n",
      "Epoch 0, Batch 10, Loss: 0.831483006477356\n",
      "Epoch 0, Batch 20, Loss: 0.5115661025047302\n",
      "Epoch 0, Batch 30, Loss: 0.8358895182609558\n",
      "Epoch 1, Batch 0, Loss: 0.8545390963554382\n",
      "Epoch 1, Batch 10, Loss: 0.8069888949394226\n",
      "Epoch 1, Batch 20, Loss: 0.5200721621513367\n",
      "Epoch 1, Batch 30, Loss: 0.8098663687705994\n",
      "Epoch 2, Batch 0, Loss: 0.8402116298675537\n",
      "Epoch 2, Batch 10, Loss: 0.7819634675979614\n",
      "Epoch 2, Batch 20, Loss: 0.5270403623580933\n",
      "Epoch 2, Batch 30, Loss: 0.7877657413482666\n",
      "Epoch 3, Batch 0, Loss: 0.8303874731063843\n",
      "Epoch 3, Batch 10, Loss: 0.7595011591911316\n",
      "Epoch 3, Batch 20, Loss: 0.5323825478553772\n",
      "Epoch 3, Batch 30, Loss: 0.7688813209533691\n",
      "Epoch 4, Batch 0, Loss: 0.8212447166442871\n",
      "Epoch 4, Batch 10, Loss: 0.739532470703125\n",
      "Epoch 4, Batch 20, Loss: 0.5364087820053101\n",
      "Epoch 4, Batch 30, Loss: 0.7528592944145203\n",
      "Epoch 5, Batch 0, Loss: 0.814746081829071\n",
      "Epoch 5, Batch 10, Loss: 0.7228638529777527\n",
      "Epoch 5, Batch 20, Loss: 0.5402035117149353\n",
      "Epoch 5, Batch 30, Loss: 0.738863468170166\n",
      "Epoch 6, Batch 0, Loss: 0.8107298612594604\n",
      "Epoch 6, Batch 10, Loss: 0.7080094814300537\n",
      "Epoch 6, Batch 20, Loss: 0.5426852107048035\n",
      "Epoch 6, Batch 30, Loss: 0.7273232340812683\n",
      "Epoch 7, Batch 0, Loss: 0.8084467649459839\n",
      "Epoch 7, Batch 10, Loss: 0.6945617198944092\n",
      "Epoch 7, Batch 20, Loss: 0.5439366102218628\n",
      "Epoch 7, Batch 30, Loss: 0.7176421880722046\n",
      "Epoch 8, Batch 0, Loss: 0.8081011176109314\n",
      "Epoch 8, Batch 10, Loss: 0.6814837455749512\n",
      "Epoch 8, Batch 20, Loss: 0.5433379411697388\n",
      "Epoch 8, Batch 30, Loss: 0.7092549204826355\n",
      "Epoch 9, Batch 0, Loss: 0.8104343414306641\n",
      "Epoch 9, Batch 10, Loss: 0.6692860126495361\n",
      "Epoch 9, Batch 20, Loss: 0.5409029126167297\n",
      "Epoch 9, Batch 30, Loss: 0.7017086744308472\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 6\n",
    "num_batches = node_fts.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx in range(num_batches):\n",
    "        node_fts_batch = node_fts[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        edge_fts_batch = edge_fts[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        graph_fts_batch = graph_fts[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        adj_mat_batch = adj_mat[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        hidden_batch = hidden[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "\n",
    "        y_batch = labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        \n",
    "        params, opt_state, loss = train_step(params, opt_state, rng, node_fts_batch, edge_fts_batch, graph_fts_batch, adj_mat_batch, hidden_batch, y_batch)\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, y):\n",
    "    logits = myNet_d2_apply(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden)\n",
    "    loss = jnp.mean(optax.softmax_cross_entropy(logits, jax.nn.one_hot(y, 2)))\n",
    "    return loss\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = optax.adam(learning_rate)\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "params = myNet_d2_init(rng, fnode_fts, fedge_fts, fgraph_fts, adj_mat, hidden)\n",
    "\n",
    "opt_state = optimizer.init(params)\n",
    "\n",
    "@jax.jit\n",
    "def train_step(params, opt_state, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, y):\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params, rng, node_fts, edge_fts, graph_fts, adj_mat, hidden, y)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 0.9538387656211853\n",
      "Epoch 0, Batch 10, Loss: 0.6665393114089966\n",
      "Epoch 0, Batch 20, Loss: 0.6276198029518127\n",
      "Epoch 0, Batch 30, Loss: 0.8215416669845581\n",
      "Epoch 1, Batch 0, Loss: 0.7126345634460449\n",
      "Epoch 1, Batch 10, Loss: 0.6422020196914673\n",
      "Epoch 1, Batch 20, Loss: 0.5992827415466309\n",
      "Epoch 1, Batch 30, Loss: 0.7916746139526367\n",
      "Epoch 2, Batch 0, Loss: 0.6888958811759949\n",
      "Epoch 2, Batch 10, Loss: 0.6454041004180908\n",
      "Epoch 2, Batch 20, Loss: 0.574306845664978\n",
      "Epoch 2, Batch 30, Loss: 0.7642949819564819\n",
      "Epoch 3, Batch 0, Loss: 0.6592787504196167\n",
      "Epoch 3, Batch 10, Loss: 0.6452130079269409\n",
      "Epoch 3, Batch 20, Loss: 0.5502197742462158\n",
      "Epoch 3, Batch 30, Loss: 0.7412863969802856\n",
      "Epoch 4, Batch 0, Loss: 0.6310687065124512\n",
      "Epoch 4, Batch 10, Loss: 0.6458129286766052\n",
      "Epoch 4, Batch 20, Loss: 0.5241541862487793\n",
      "Epoch 4, Batch 30, Loss: 0.7217268943786621\n",
      "Epoch 5, Batch 0, Loss: 0.6037113666534424\n",
      "Epoch 5, Batch 10, Loss: 0.6477369666099548\n",
      "Epoch 5, Batch 20, Loss: 0.49705082178115845\n",
      "Epoch 5, Batch 30, Loss: 0.7043964266777039\n",
      "Epoch 6, Batch 0, Loss: 0.5755893588066101\n",
      "Epoch 6, Batch 10, Loss: 0.6504762172698975\n",
      "Epoch 6, Batch 20, Loss: 0.4686819911003113\n",
      "Epoch 6, Batch 30, Loss: 0.6878756880760193\n",
      "Epoch 7, Batch 0, Loss: 0.5457823276519775\n",
      "Epoch 7, Batch 10, Loss: 0.6517356038093567\n",
      "Epoch 7, Batch 20, Loss: 0.44065535068511963\n",
      "Epoch 7, Batch 30, Loss: 0.6708775758743286\n",
      "Epoch 8, Batch 0, Loss: 0.5151945352554321\n",
      "Epoch 8, Batch 10, Loss: 0.6519929766654968\n",
      "Epoch 8, Batch 20, Loss: 0.4134734272956848\n",
      "Epoch 8, Batch 30, Loss: 0.6533858776092529\n",
      "Epoch 9, Batch 0, Loss: 0.48289674520492554\n",
      "Epoch 9, Batch 10, Loss: 0.65120530128479\n",
      "Epoch 9, Batch 20, Loss: 0.3873618245124817\n",
      "Epoch 9, Batch 30, Loss: 0.635671079158783\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 6\n",
    "num_batches = node_fts.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx in range(num_batches):\n",
    "        fnode_fts_batch = fnode_fts[:, batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        fedge_fts_batch = fedge_fts[:, batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        fgraph_fts_batch = fgraph_fts[:, batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        adj_mat_batch = adj_mat[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        hidden_batch = hidden[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        y_batch = labels[batch_idx * batch_size:(batch_idx + 1) * batch_size]\n",
    "        \n",
    "        params, opt_state, loss = train_step(params, opt_state, rng, fnode_fts_batch, fedge_fts_batch, fgraph_fts_batch, adj_mat_batch, hidden_batch, y_batch)\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print(f'Epoch {epoch}, Batch {batch_idx}, Loss: {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# esempio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6547499   4.2710185 ]\n",
      " [ 0.34689993  1.204605  ]]\n"
     ]
    }
   ],
   "source": [
    "import haiku as hk\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "class MyLayer(hk.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def __call__(self, edge_fts, graph_fts, adj_mat, hidden):\n",
    "        edge_fts = hk.Linear(self.hidden_dim)(edge_fts)\n",
    "        graph_fts = hk.Linear(self.hidden_dim)(graph_fts)\n",
    "        hidden = hk.Linear(self.hidden_dim)(hidden)\n",
    "        aggregated = jnp.matmul(adj_mat, edge_fts)\n",
    "        output = aggregated + graph_fts + hidden\n",
    "        return output\n",
    "\n",
    "def model_fn(edge_fts, graph_fts, adj_mat, hidden):\n",
    "    model = MyLayer(hidden.shape[-1])\n",
    "    return model(edge_fts, graph_fts, adj_mat, hidden)\n",
    "\n",
    "model_init, model_apply = hk.transform(model_fn)\n",
    "\n",
    "# Example input data\n",
    "edge_fts = jnp.array([[1.0, 2.0], [3.0, 4.0]])  # Shape (num_edges, feature_dim)\n",
    "graph_fts = jnp.array([[1.0, 2.0]])             # Shape (num_graphs, feature_dim)\n",
    "adj_mat = jnp.array([[0, 1], [1, 0]])           # Shape (num_nodes, num_nodes)\n",
    "hidden = jnp.array([[0.5, 0.5]])                # Shape (num_nodes, hidden_dim)\n",
    "\n",
    "rng = jax.random.PRNGKey(42)\n",
    "\n",
    "# Initialize the model parameters\n",
    "params = model_init(rng, edge_fts, graph_fts, adj_mat, hidden)\n",
    "\n",
    "# Perform a forward pass\n",
    "output = model_apply(params, rng, edge_fts, graph_fts, adj_mat, hidden)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gh 0\n",
      "h 0\n",
      "d2_inverses[g] 0\n",
      "gh 1\n",
      "h 1\n",
      "d2_inverses[g] 0\n",
      "gh 2\n",
      "h 2\n",
      "d2_inverses[g] 0\n",
      "gh 3\n",
      "h 3\n",
      "d2_inverses[g] 0\n",
      "gh 1\n",
      "h 0\n",
      "d2_inverses[g] 1\n",
      "gh 0\n",
      "h 1\n",
      "d2_inverses[g] 1\n",
      "gh 3\n",
      "h 2\n",
      "d2_inverses[g] 1\n",
      "gh 2\n",
      "h 3\n",
      "d2_inverses[g] 1\n",
      "gh 2\n",
      "h 0\n",
      "d2_inverses[g] 2\n",
      "gh 3\n",
      "h 1\n",
      "d2_inverses[g] 2\n",
      "gh 0\n",
      "h 2\n",
      "d2_inverses[g] 2\n",
      "gh 1\n",
      "h 3\n",
      "d2_inverses[g] 2\n",
      "gh 3\n",
      "h 0\n",
      "d2_inverses[g] 3\n",
      "gh 2\n",
      "h 1\n",
      "d2_inverses[g] 3\n",
      "gh 1\n",
      "h 2\n",
      "d2_inverses[g] 3\n",
      "gh 0\n",
      "h 3\n",
      "d2_inverses[g] 3\n"
     ]
    }
   ],
   "source": [
    "num_d2_actions = 4\n",
    "\n",
    "d2_inverses = [\n",
    "0, 1, 2, 3  # All members of D_2 are self-inverses!\n",
    "]\n",
    "\n",
    "d2_multiply = [\n",
    "[0, 1, 2, 3],\n",
    "[1, 0, 3, 2],\n",
    "[2, 3, 0, 1],\n",
    "[3, 2, 1, 0],\n",
    "]\n",
    "\n",
    "# assert len(node_fts) == num_d2_actions\n",
    "# assert len(edge_fts) == num_d2_actions\n",
    "# assert len(graph_fts) == num_d2_actions\n",
    "\n",
    "ret_nodes = []\n",
    "adj_mat = jnp.ones_like(adj_mat)\n",
    "\n",
    "for g in range(num_d2_actions):\n",
    "    emb_values = []\n",
    "    for h in range(num_d2_actions):\n",
    "        gh = d2_multiply[d2_inverses[g]][h]\n",
    "        # print(\"gh\", gh)\n",
    "        # print(\"h\", h)\n",
    "        # print(\"d2_inverses[g]\", d2_inverses[g])\n",
    "        node_features = jnp.concatenate(\n",
    "            (node_fts[g], node_fts[gh]),\n",
    "            axis=-1)\n",
    "        edge_features = jnp.concatenate(\n",
    "            (edge_fts[g], edge_fts[gh]),\n",
    "            axis=-1)\n",
    "        graph_features = jnp.concatenate(\n",
    "            (graph_fts[g], graph_fts[gh]),\n",
    "            axis=-1)\n",
    "    #     cell_embedding = model_apply(params, rng,\n",
    "    #         node_fts=node_features,\n",
    "    #         edge_fts=edge_features,\n",
    "    #         graph_fts=graph_features,\n",
    "    #         adj_mat=adj_mat,\n",
    "    #         hidden=hidden\n",
    "    #     )\n",
    "    #     emb_values.append(cell_embedding[0])\n",
    "    # ret_nodes.append(\n",
    "    # jnp.mean(jnp.stack(emb_values, axis=0), axis=0)\n",
    "    # )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
